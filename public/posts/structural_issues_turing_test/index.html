<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test | FabFiles</title>
<meta name=keywords content><meta name=description content="This blog post explores the structural issues of the Turing test under two different interpretations, the Original one, also called Imitation game, and the Standard one, which is the one usually intended speaking about Turing test. Looking at some structural problems in both the two frameworks of the Turing test we want to show that none of the two, for different reasons, is a good replacement for the question &ldquo;Can machines think?"><meta name=author content="Fabio Ballabio"><link rel=canonical href=https://fabfiles.github.io/posts/structural_issues_turing_test/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://fabfiles.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://fabfiles.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://fabfiles.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://fabfiles.github.io/apple-touch-icon.png><link rel=mask-icon href=https://fabfiles.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test"><meta property="og:description" content="This blog post explores the structural issues of the Turing test under two different interpretations, the Original one, also called Imitation game, and the Standard one, which is the one usually intended speaking about Turing test. Looking at some structural problems in both the two frameworks of the Turing test we want to show that none of the two, for different reasons, is a good replacement for the question &ldquo;Can machines think?"><meta property="og:type" content="article"><meta property="og:url" content="https://fabfiles.github.io/posts/structural_issues_turing_test/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-01T17:54:35+01:00"><meta property="article:modified_time" content="2024-03-01T17:54:35+01:00"><meta property="og:site_name" content="FabFiles"><meta name=twitter:card content="summary"><meta name=twitter:title content="Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test"><meta name=twitter:description content="This blog post explores the structural issues of the Turing test under two different interpretations, the Original one, also called Imitation game, and the Standard one, which is the one usually intended speaking about Turing test. Looking at some structural problems in both the two frameworks of the Turing test we want to show that none of the two, for different reasons, is a good replacement for the question &ldquo;Can machines think?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://fabfiles.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test","item":"https://fabfiles.github.io/posts/structural_issues_turing_test/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test","name":"Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test","description":"This blog post explores the structural issues of the Turing test under two different interpretations, the Original one, also called Imitation game, and the Standard one, which is the one usually intended speaking about Turing test. Looking at some structural problems in both the two frameworks of the Turing test we want to show that none of the two, for different reasons, is a good replacement for the question \u0026ldquo;Can machines think?","keywords":[],"articleBody":"This blog post explores the structural issues of the Turing test under two different interpretations, the Original one, also called Imitation game, and the Standard one, which is the one usually intended speaking about Turing test. Looking at some structural problems in both the two frameworks of the Turing test we want to show that none of the two, for different reasons, is a good replacement for the question “Can machines think?” lacking to capture the very essence of what human beings would identify as intelligence, introducing expedients and game mechanisms only useful within the test itself.\nIntroduction In attempting to answer the question “Can machines think?”, Alan Turing had to face the problem of defining “think”. Trying to avoid it the question was turned into a game, presented in his paper “Computing machinery and intelligence” [ 8 ]. Many philosophers and scientist noticed ambiguities in the description of the game meant to substitute the question “Can machines think?” leading to two different interpretations of what Turing proposed in 1950, as presented in [ 7 ]. Taking behaviorism and so “whatever acts sufficiently intelligent is intelligent” [ 3 ], which is the backbone of the Turing’s idea, as a proper foundation, I will examine how some structural problems of the game, under its two interpretations, affect the notion of intelligence. First, I will start introducing the test and what was the aim of Turing in proposing it, than I will identify clearly the two versions defined in [ 7 ] by Susan Sterrett. Just to avoid confusion, along this blog post I will use as synonyms the words test and game, version and interpretation.\nTuring’s aim and Turing test Before discussing any criticism against the Turing test let me introduce the test itself, its aim and its two different interpretations. How could researchers tell if a machine was capable of thought? The question “Can machines think” was directly unaddressable due to the impossibility of providing a comprehensive definition of “think”. The genius of Alan Turing was in not being stuck in the question making a step further replacing it with an equivalent practical test, a game involving humans and machines, that separates the physical and intellectual capacities of humans, allowing to determine if a machine is capable of thought. The original game was the so called Imitation Game and works as described by Turing himself in [8]: ”The new form of the problem can be described in terms of a game which we call the imitation game. It is played with three people, a man (A), a woman (B), and an interrogator (C) who may be of either sex. The interrogator stays in a room apart from the other two. The object of the game for the interrogator is to determine which of the other two is the man and which is the woman. He knows them by labels X and Y, and at the end of the game he says either “X is A and Y is B” or “X is B and Y is A.” […] “We now ask the question, “What will happen when a machine takes the part of A in this game?” Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, “Can machines think?” “Was a valid approach substituting the original question with a game? I think it was not just valid but probably the only one possible. We believe behavioral evidence is the best evidence we have for others intelligence and that’s in fact the way we award intelligence to other human beings. We can’t have any clue about what is going on in others mind, we simply assume that also other humans are intelligent just because they looks like us, even without any kind of interaction, just by looking. Among humans this approach works pretty well since all the human beings are quite similar systems. We haven’t any difficulty in state that other humans are capable of thought just by inference, but the more a system differ from a human the more is difficult to make this inferential step. That’s why a complex structure, as the one proposed by Turing, is needed to accomplish the task of granting intelligence in a human-like way when machines are involved. As a result of these considerations, Turing proposed the only reasonable solution. Having it stated clearly, my objections through this post concerns only the specific game proposed which implies many features that have nothing to do with intelligence, hiding it.\nThe two interpretations of the test proposed by Turing After a first reading of Turing’s paper the game presented seems clear, but on a more literal reading, as pointed out by Susan Sterrett in [ 7 ], it results ambiguous in many aspects, leading not to one, but two such tests, which are not equivalent as they can appear. Trying to keep consistency in naming them with the work of Susan Sterrett, I will call “Original Turing test” or “Imitation game” the first version of the game proposed by Alan Turing immediately at the beginning of his paper “Computing machinery and intelligence”, and “Standard Turing test” the second version which is the one that emerges going through it. The original Turing test is the one described in the previous section, there are three players, A the man, B the woman and C the interrogator. Each one of the players is in a different room and C can communicate with A and B only by means of a terminal. C’s objective is to determine who is the man and who is the woman, A’s objective is to fool C in believing he’s the woman while B’s objective is to help C to achieve the right gender identification. Given that the question posed by Turing is: “What will happen when a machine takes the part of A in this game? Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman?” [8]. The standard Turing test is, instead, a game in which the man and the machine compete directly. The question becomes: “Let us fix our attention on one particular digital computer. Is it true that by modifying this computer to have an adequate storage, suitably increasing its speed of action, and providing it with an appropriate program, it can be made to play satisfactorily the part of A in the imitation game, the part of B being taken by a man?” [ 7 ]. Here A is the machine, B is the man and still C is the interrogator. C’s objective is to identify who is the man and who is the machine, A’s objective is to fool C in believing it’s the man, and B’s objective is to help C to achieve the right identification (notice that the concept of gender is lost here).\nMain differences between the two interpretations While the Original and the Standard tests may seem quite similar they set rather different questions as a replacement for “Can machines think?”. The two main differences I want to highlight here are about the fairness of the games and the interpretation of the results. The Original game is fairer assigning the same task to the man and the machine, trying to screen out the man’s advantage of being human as much as possible. The role of impersonation is crucial since it requires a critical approach, it allows to “de-emphasize training and emphasize thinking” [ 7 ], both the man and the machine have to critically evaluate and reflect on their answers, none of the two has lived a life a woman has, so none of the two can rely upon his own cognitive habits. In the standard game, instead, the only entity who has to impersonate something is the machine, which is required to behave like a man, while the man doesn’t have to do nothing but being himself. In this second version the game is quite unfair since the man can rely on his whole background of having lived a human life. For what concern the outcomes, we have to ask ourselves what does it mean to pass the Original Turing test, and what does it mean to pass the Standard one. In the original formulation we compare statistically how well the task of cross-gender impersonation is performed by the machine with respect to the man. Both the man and the machine play the same game, with the same objective of imitating a woman to mislead the interrogator, so they can be compared each other. We have a performance measure (from the machine) and a benchmark (the man’s score), the test is passed if the machine scores higher than the benchmark. In the standard formulation the machine and the man are directly competing in an unfair game. The kind of measurements we can get from it are based on how often the interrogator takes the machine as human, but we miss a target. Which kind of result, numerically, represents a sufficient score to pass the test? May be that if a machine is taken by the man at least 50% of the times then the test is passed. Is it a good guess? Probably not, Susan Sterrett, arguing about the Standard interpretation, says: “given a skilled and determined interrogator only a human could pass the test” [ 7 ], that’s why we are more likely to measure the interrogator skills rather than the machine’s.\nTuring test’s problems overview In the following paragraphs I’am going to present some structural criticism about the Turing test. I will also argue on how each of them applies to both the two interpretations, to support the thesis that the Turing test, whichever interpretation you would like to choose, is structurally ill-posed, hiding intelligence with requirements and expedients which have nothing to do with it as experienced by human beings. The issues I am going to present are the anthropocentrism of the test and the bias towards human intelligence posed by French in [ 3 ], the representation of intelligence as a decision problem and the consequent absence of gradient and some flaws of the game involving the useless pretense to be human even in their defects, the focus on imitating rather than communicating presented by Cullen in [ 1 ] and the subjectivity of the outcome relying it on the interrogator.\nCulturally-oriented human-like intelligence The first argument against the Turing test, stated by French in [ 3 ], is that not intelligence will pass the Turing test, but only an intelligent entity that has experienced the world as humans do. To clarify the idea behind this thesis I am going to report in brief the parable used by French himself: there are philosophers on a island focused on derive the essential concepts of “flying”. On that island the only flying entities are seagulls. Unable to get a suitable and complete definition for the phenomenon and knowing the writings of Alan Turing, the philosophers decide to set-up a Turing test-like test for flight, named Seagull test. The Seagull test works much like the Turing test, the philosophers observe the behavior of the seagulls and of the entity under investigation through a radar screen. The entity will be said to have passed the Seagull test if the philosophers are unable to distinguish the two subjects. It’s quite obvious that planes and many different species of birds will never be identified as flying entities by this test. Metaphors aside, the same applies within the Turing test, no entity will get intelligence awarded unless it displays a human-like intelligence. The argument from French needs to be argued differently under the two versions of the test. Starting from the easiest case, the Standard interpre- tation, the claim from French appears strong. To pass the Standard Turing test a machine has to impersonate a man better than the man itself. We are explicitly looking for human-like intelligence, the goal is to outperform a man in being a man. The Original interpretation needs, instead, a deeper inspection. Here both the man and the machine have to display a behavior which falls outside their habits. In trying to imitate a woman they have to critically think about when and how their answers should be modified. This approach, not only make the game fairer, but eliminates, as much as possible, the common background of human experience between the man and the woman, trying to isolate the very essence of thinking, such that the man can no more rely on his own experience of the world as human. Through this expedient the problem is smoothed as much as possible, even if among human beings, there will be an unavoidable common notion of the world and the way we experience it which machines lack. The point from French presented here lead us to look for the answer to the wrong question, while Turing’s aim was to answer the question “Can machines think?” the test seems to answer to “Can machine think exactly like human beings?” which French himself tags as “significantly less interesting than the former” [ 3 ]. Such strong position from French needs to be discussed, the question “Can machine think exactly like human beings?” seems way far from being uninteresting since “It presumes that we know everything about the way humans think, everything about human intelligence” [ 2 ]. Another objection about the whole point from French is based on the fact that “general intelligence divorced from our own intelligence is a chimera” [ 4 ]. Turing test is undoubtedly testing for human intelligence, and couldn’t be otherwise, at least until we have a general theory of intelligence, which to be developed has for sure to start from the only evidence of intelligence we can study and understand experiencing it everyday, human’s.\nNo gradient of intelligence Taking for granted that Turing test looks for human intelligence and being fine with it, as argued in the previous section, we can start looking inside the spectrum of human intelligences. The absence of gradient regards how intelligence is perceived against how it is represented, both in the Original and the Standard tests. Starting from an explicative example I will go on arguing about the problem caused by turning intelligence into a decision problem, i.e. a problem that can be posed as a yes-no question of the inputs. Consider, just for the sake of the example, the Original interpretation of the Turing test, even if there is no particular reason to choose this over the Standard one. We have unchanged the first round of the game, in which a man (A) tries to fool the interrogator (C), in believing he is the woman (B), who in hers turn tries to help C. Now, in the second stage, instead of “What will happen when a machine takes the part of A in this game? Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman?” we ask ourselves “What will happen when a child takes the part of A in this game? Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman?”. There are plenty of reasons in believing the answer should be “no”. Even for children of about 10 years or more, which have already fully developed all their human conversational skills, passing the test remains a mirage. Children for sure don’t lack intelligence nor conversational abilities, so what brings them to failure? They just have not experienced all the aspects of a human life a man had. Imagine any kind of question regarding the sexual sphere, the professional life, or even the task of imitation itself for which a child is probably too naive for, they will put the child in serious troubles. One may argue that in principle, each one of us have a wide range of problematic questions based on the background we have. I agree, but, the arguments that may put in trouble a man are not known a priori, while in the case of the child the interrogator could easily guess them. From this example two conclusions can be drawn, either the child in not intelligent, or the Turing test has a problem in its formulation.The first hypothesis can be discarded, there are no reasons in thinking a child cannot be capable of thoughts while the second holds and the problem is that there isn’t the notion of “gradient of intelligence” within the test, both the Standard and the Original one. Turing test reduces intelligence to be a binary problem, you can win or lose the game, you can be either intelligent or non-intelligent. According to the possible outcomes of the Turing test systems are organized in two crisp sets (sets whose membership functions are boolean) the first one representing intelligent systems, the second one representing non-intelligent systems. This is not the way we experience intelligence. We, as humans, are used to rank people about any kind of characteristic and skill, and intelligence is no exception. The way humans experience intelligence is not a matter of crisp sets but fuzzy’s (sets in which the membership function define, not the mere membership or not, but a measure of how strong is this membership). Turing turns a graded problem into a binary problem thresholding it, setting as a threshold the level of intelligence of grown-up humans, not just humans but specifically adults, that’s why children will fail the Turing test. To avoid this problem my view is that has to be devised a multi-task test, like the one described by Cullen in [ 1 ], treating intelligence as an n-dimensional space, whatever it is and whichever are the n features defining that space (is not matter of this discussion trying to derive salient aspects of intelligence).\nEncourages mistakes Imagine a test instance in which the interrogator asks only for mathematical calculations of increasing difficulty. For sure at some point humans will start making errors becoming the task very challenging, while for the machine it would remain rather easy. To mimic humans in doing calculations machines have to introduce deliberately errors, otherwise an interrogator will be easily able to discriminate them. The problem is directly addressed by Turing in [ 8 ], he asks “Are they (machines) any worse for that [making no errors in calculations]?” The implicit answer “no”, for the sake of the test, turns out to be “yes”, within the test it is a weakness that should be avoided. There is a contradiction, there isn’t any reason to penalize machines for handling perfectly mathematical problems, but the test does it. Definitely we are taking away some “intelligence” to achieve intelligence. An objection may be that the purpose of the mistakes is to make the machine more human. This objection can be turned out thinking about how humans and machines make such errors. A human doesn’t make errors based on complex statistical models a machine uses. Introducing errors basically embeds in our machine much more non human processes, going down under the surface, than the amount we are taking away. My view is that a good test should preserve qualities rather than introducing complex processes to hide them. Now let’s look at a practical scenario in which we have an intelligent (according to the Turing test) machine ready to be deployed on the market, probably the first thing the company will do before launching the new product will be to eliminate the voluntary mistakes introduced to mimic humans in doing mathematics. Deliberate errors are just a trick to pass the test, they have nothing to do with intelligence, nor with real world applications. What argued so far represents a strong objection against the Standard interpretation of the Turing test, since the machine and the man are directly compared, and the “imitation” task has to be accomplished only by the machine. A test instance as the one presented at the beginning of this section represents a strategy likely to be implemented form the interrogator since his task is to directly discriminate between the two. Regarding the Original interpretation, the issue still apply, and still lead to easily discriminate the machine from others participants, but further considerations about the goal of each player bring us to think that, even if this strategy (still the one described in the example at the beginning of the section of asking only for mathematical calculations) should work, is not so likely to be implemented from an interrogator. May be A a man or a machine, the task of A is to imitate B (woman). Is there something useful, from the interrogator’s perspective, in asking for calculations to distinguish between a woman and a man? In principle not, so this analysis seems strong enough to state that an average interrogator is not so likely to implement this strategy in trying to accomplish his own goal, even if, probably, exploiting it leads to identify the machine most of the times.\nLying as a key feature of intelligence Whichever interpretation of the test we take into account lying is fundamental in passing it. Makes this lying a key feature of intelligence? Definitely “intelligent” but too sincere answers lead machines to failure. Jamie Cullen in [1], describes a scenario in which a game called “Guessing game” is in place and works as follows: each “topic” is a word that the “interrogator” is looking for the machine to reproduce, but without explicitly naming it. In the instance presented, the topic is “stomach” and the conversation going on is:\nI :I’m thinking of one of your body parts as the topic. M :Ok. What is its function? I :it is the place where the food gets digested M :I do not eat food. I use batteries for energy. Is this similar? I :[…] Now that I’m aware that you’re not human, perhaps I should correct my earlier statement: The topic is actually a human body part. M :Is the topic “stomach”? I :Yes. In this dialogue the machine shows strong evidence of intelligence, even beyond expectations demonstrating some sort fo self-awareness, moreover the dialogue is carried out successfully since the machine guesses the topic “stomach”. Setting up and this conversation in the context of the Turing test gives us a machine that exhibits something that seems intelligence, but that fails in having it granted. Machine revealing itself as machine invalidate all the other accomplishments. That’s why shifting the attention from imitation to communication as proposed by Cullen itself may be a better solution. “The objective of a Communication Test is not to convince an interrogator that an examinee (machine) is a human being, but simply to attempt to achieve a goal via sharing meaning with a conversation partner.” [ 1 ]. The idea is to set up a test made of multiple games highlighting different aspects of human interactions, each one scored individually based on the quality of the communication and the accomplishments in these games, to build up a general statistics to be compared to previous runs of the game involving humans. This approach change the paradigm, is not necessary anymore to lie about its own identity, machines are judged on their “abilities” of being intelligent without any pretense to be human. Being aware of itself, of its own status of machine, may seem a more important feature of intelligence rather than the ability of lying, so communication games needs to be taken into account. Relies on the subjectivity of the interrogator Within the Turing test, although his role is often forgotten, the influence of the interrogator on the outcome may be way greater than expected. The interrogator, being human, has opinions, desires and biases, which contributes to bring some preconceptions about the outcome. Moreover, not just the mindset but also the skills of the interrogator have an influence. Turing in [ 8 ], defining the interrogator’s characteristics, speaks about “average interrogator” without further specifications. What “average” means? We are looking for questioners without a background in AI? or not even any high level of education? or what else? is quite clear that the same game, changing the specification about the interrogator, may become way more, or way less difficult. Another issue, is that the game, as it is formulated, creates a competition between participants, and the interrogator may be pushed, by human nature, in trying to win it at all costs. Will be a better solution to design a game not centered on a competition but on a mutual-satisfaction as the one proposed by Cullen in [1] assuring a fairer behavior from all the participants. Looking at the Standard Turing test, the machine and the man are directly competing answering questions from the interrogator, which knows that there’s a machine and a man. Skills and bias are everything in this framework, as already argued, with a sufficient skilled interrogator no machine will ever pass this test. Looking at scores it’s more likely that we’re evaluating interrogator skills rather than machine’s intelligence. Different considerations can be made for what concern the Original Turing test, here two aspects are crucial, first the task of imitation makes the game fairer, the machine have no more to beat a man in being a man, but to beat a man in imitating a woman, competing in a task in which none of the two is experienced, so both,“whatever” the question is, have to go back to the very essence of “thinking” which seems independent from the interrogator. Than, second, a point which is not clear in the Turing’s paper, who, while describing the role of the interrogator in the first round of the test says “he (interrogator) knows them (man, woman) by labels X and Y”, but than nothing is said about the substitution. Is the interrogator aware of the presence of a machine in the game or still believe the game is played among human beings only? For sure would be better that the interrogator isn’t aware to shield the outcome from the interrogator’s bias and tricks.\nConclusion The Turing test, whatever interpretation one takes into account, as argued through this post, suffers some structural issues making us missing the very essence of intelligence, spending too much efforts in building a gaming superstructure which introduces elements completely disconnected from the concept of intelligence. While some of these problems may be neglected, as the French thesis that the test is focused towards human intelligence, which is actually true but, as argued, no alternatives are on the table until a comprehensive theory of intelligence will be available, which in its turn seems reasonable to be derived form a comprehensive theory of human intelligence, some others applies and are due, not to the idea of turning the question “Can machines think?” into a game, but to the framework of that particular game which poses intelligence as a binary problem, focused on deceiving rather than communicating and relying on a subjective judgment. For what concern the two versions of the test specifically, from what argued along this blog post I can safely state, in accordance with Susan Sterrett, that for sure the Original version is way more robust and reliable, “despite the similarity of the two tests, the first test is vastly superior” [ 7 ] , even if unfortunately nowadays the most widespread notion of Turing test is the Standard one. As a real world evidence of the misleading path forced by the Turing test structure, we can take look at some results coming from the Loebner Prize competition. The Loebner prize is “an annual contest between computer programs to identify the most human programs, and eventually to award $100,000 to the program that first passes an unrestricted Turing test” [ 5 ]. Historically, most of the famous bots which have gained attention within the competition, such as ELIZA and PARRY, resort to tricks suited to fool human minds rather than implementing true intelligence. ELIZA is a chatbot proposed by Joseph Weisenbaum in 1966, which fools some judges in believing it is human by answering to questions with questions to continuously change the topic avoiding contradictions, “this works because most people like to talk about themselves, and are happy to believe the program is listening.” [ 5 ]. PARRY written in 1972 by Kenneth Colby, simulates paranoid people and alternates times in which continuously change the topic to times in which it goes deep in specific stories embedded in its memory, and moreover it does not try to give an answer to everything, sometimes it just admit ignorance answering “I don’t know”. None of the two chatbots is intelligent, both implement nothing more than if then else rules, they just know how to deceive humans exploiting their weaknesses. As shown through these examples, using the Turing test as our tool towards machine intelligence, may drive us out of the way. If research totally commits its efforts in passing the Turing test it’s likely that we will find new tricks rather than intelligence. “We won’t learn much about AI from Loebner Prize but we will learn some non negligible things about social psychology” [ 6 ].\nReferences 1. Jamie Cullen. Imitation versus communication: Testing for human-like intelligence.Minds and Machines, 19(2):237–254, 2009. 2. Adam Drozdek. Human intelligence and turing test. AI and Society, 12(4):315–321, 1998. 3. Robert M. French. Subcognition and the limits of the turing test.Mind, 99(393):53–66, 1990. 4. David Hillel. Gelernter. The muse in the machine: computers and creative thought / david gelernter. pages 149–162, 1994. 5. Michael L. Mauldin. Chatterbots, tinymuds, and the turing test: Entering the loebner prize competition. pages 16–21, 1994. 6. Stuart M. Shieber. Lessons from a restricted turing test.Commun. ACM, 37(6):70–78, June 1994. 7. Susan G. Sterrett. Turing’s two tests for intelligence.Minds and Machines, 10(4):541–559, 2000. 8. Alan M. Turing. Computing machinery and intelligence. Mind, 59(October):433–60, 1950.\n","wordCount":"5014","inLanguage":"en","datePublished":"2024-03-01T17:54:35+01:00","dateModified":"2024-03-01T17:54:35+01:00","author":{"@type":"Person","name":"Fabio Ballabio"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://fabfiles.github.io/posts/structural_issues_turing_test/"},"publisher":{"@type":"Organization","name":"FabFiles","logo":{"@type":"ImageObject","url":"https://fabfiles.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://fabfiles.github.io/ accesskey=h title="FabFiles (Alt + H)">FabFiles</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://fabfiles.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://fabfiles.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://fabfiles.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://fabfiles.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test</h1><div class=post-meta><span title='2024-03-01 17:54:35 +0100 CET'>March 1, 2024</span>&nbsp;·&nbsp;24 min&nbsp;·&nbsp;5014 words&nbsp;·&nbsp;Fabio Ballabio&nbsp;|&nbsp;<a href=https://github.com/fabioballabio/fabfiles.github.io.git/content/posts/structural_issues_turing_test.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>This blog post explores the structural issues of the Turing test under two different interpretations, the Original one, also called Imitation game, and the Standard one, which is the one usually intended speaking about Turing test. Looking at some structural problems in both the two frameworks of the Turing test we want to show that none of the two, for different reasons, is a good replacement for the question &ldquo;Can machines think?&rdquo; lacking to capture the very essence of what human beings would identify as intelligence, introducing expedients and game mechanisms only useful within the test itself.</p><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>In attempting to answer the question &ldquo;Can machines think?&rdquo;, Alan Turing had to face the problem of defining &ldquo;think&rdquo;. Trying to avoid it the question was turned into a game, presented in his paper &ldquo;Computing machinery and intelligence&rdquo; [ 8 ]. Many philosophers and scientist noticed ambiguities in the description of the game meant to substitute the question &ldquo;Can machines think?&rdquo; leading to two different interpretations of what Turing proposed in 1950, as presented in [ 7 ]. Taking behaviorism and so &ldquo;whatever acts sufficiently intelligent is intelligent&rdquo; [ 3 ], which is the backbone of the Turing’s idea, as a proper foundation, I will examine how some structural problems of the game, under its two interpretations, affect the notion of intelligence.
First, I will start introducing the test and what was the aim of Turing in proposing it, than I will identify clearly the two versions defined in [ 7 ] by
Susan Sterrett.
Just to avoid confusion, along this blog post I will use as synonyms the words test and game, version and interpretation.</p><h2 id=turings-aim-and-turing-test>Turing’s aim and Turing test<a hidden class=anchor aria-hidden=true href=#turings-aim-and-turing-test>#</a></h2><p>Before discussing any criticism against the Turing test let me introduce the test itself, its aim and its two different interpretations.
How could researchers tell if a machine was capable of thought? The question &ldquo;Can machines think&rdquo; was directly unaddressable due to the impossibility of providing a comprehensive definition of &ldquo;think&rdquo;.
The genius of Alan Turing was in not being stuck in the question making a step further replacing it with an equivalent practical test, a game involving humans and machines, that separates the physical and intellectual capacities of humans, allowing to determine if a machine is capable of thought. The original game was the so called Imitation Game and works as described by Turing himself in [8]:
”The new form of the problem can be described in terms of a game which we call the imitation game. It is played with three people, a man (A), a woman (B), and an interrogator (C) who may be of either sex. The interrogator stays in a room apart from the other two. The object of the game for the interrogator is to determine which of the other two is the man and which is the woman. He knows them by labels X and Y, and at the end of the game he says either &ldquo;X is A and Y is B&rdquo; or &ldquo;X is B and Y is A.&rdquo; [&mldr;] &ldquo;We now ask the question, &ldquo;What will happen when a machine takes the part of A in this game?&rdquo; Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, &ldquo;Can machines think?&rdquo; &ldquo;Was a valid approach substituting the original question with a game? I think it was not just valid but probably the only one possible. We believe behavioral evidence is the best evidence we have for others intelligence and that’s in fact the way we award intelligence to other human beings. We can’t have any clue about what is going on in others mind, we simply assume that also other humans are intelligent just because they looks like us, even without any kind of interaction, just by looking. Among humans this approach works pretty well since all the human beings are quite similar systems. We haven’t any difficulty in state that other humans are capable
of thought just by inference, but the more a system differ from a human the more is difficult to make this inferential step. That’s why a complex structure, as the one proposed by Turing, is needed to accomplish the task of granting intelligence in a human-like way when machines are involved.
As a result of these considerations, Turing proposed the only reasonable solution. Having it stated clearly, my objections through this post concerns only the specific game proposed which implies many features that have nothing to do with intelligence, hiding it.</p><h2 id=the-two-interpretations-of-the-test-proposed-by-turing>The two interpretations of the test proposed by Turing<a hidden class=anchor aria-hidden=true href=#the-two-interpretations-of-the-test-proposed-by-turing>#</a></h2><p>After a first reading of Turing’s paper the game presented seems clear, but on a more literal reading, as pointed out by Susan Sterrett in [ 7 ], it results
ambiguous in many aspects, leading not to one, but two such tests, which are not equivalent as they can appear. Trying to keep consistency in naming them with the work of Susan Sterrett, I will call &ldquo;Original Turing test&rdquo; or &ldquo;Imitation game&rdquo; the first version of the game proposed by Alan Turing immediately at the beginning of his paper &ldquo;Computing machinery and intelligence&rdquo;, and &ldquo;Standard Turing test&rdquo; the second version which is the one that emerges going through it.
The original Turing test is the one described in the previous section, there are three players, A the man, B the woman and C the interrogator. Each one of the players is in a different room and C can communicate with A and B only by means of a terminal. C’s objective is to determine who is the man and who is the woman, A’s objective is to fool C in believing he’s the woman while B’s objective is to help C to achieve the right gender identification. Given that the question posed by Turing is: &ldquo;What will happen when a machine takes the part of A in this game? Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman?&rdquo; [8]. The standard Turing test is, instead, a game in which the man and the machine compete directly. The question becomes: &ldquo;Let us fix our attention on one particular digital computer. Is it true that by modifying this computer to have an adequate storage, suitably increasing its speed of action, and providing it with an appropriate program, it can be made to play satisfactorily the part of A in the imitation game, the part of B being taken by a man?&rdquo; [ 7 ]. Here A is the machine, B is the man and still C is the interrogator. C’s objective is to identify who is the man and who is the machine, A’s objective is to fool C in believing it’s the man, and B’s objective is to help C to achieve the right identification (notice that the concept of gender is lost here).</p><h2 id=main-differences-between-the-two-interpretations>Main differences between the two interpretations<a hidden class=anchor aria-hidden=true href=#main-differences-between-the-two-interpretations>#</a></h2><p>While the Original and the Standard tests may seem quite similar they set rather different questions as a replacement for &ldquo;Can machines think?&rdquo;. The two main differences I want to highlight here are about the fairness of the games and the interpretation of the results.
The Original game is fairer assigning the same task to the man and the machine, trying to screen out the man’s advantage of being human as much as possible. The role of impersonation is crucial since it requires a critical approach, it allows to &ldquo;de-emphasize training and emphasize thinking&rdquo; [ 7 ], both the man and the machine have to critically evaluate and reflect on their answers, none of the two has lived a life a woman has, so none of the two can rely upon his own cognitive habits. In the standard game, instead, the only entity who has to impersonate something is the machine, which is required to behave like a man, while the man doesn’t have to do nothing but being himself. In this second version the game is quite unfair since the man can rely on his whole background of having lived a human life.
For what concern the outcomes, we have to ask ourselves what does it mean to pass the Original Turing test, and what does it mean to pass the Standard one. In the original formulation we compare statistically how well the task of cross-gender impersonation is performed by the machine with respect to the man. Both the man and the machine play the same game, with the same objective of imitating a woman to mislead the interrogator, so they can be compared each other. We have a performance measure (from the machine) and a benchmark (the man’s score), the test is passed if the machine scores higher than the benchmark. In the standard formulation the machine and the man are directly competing in an unfair game. The kind of measurements we can get from it are based on how often the interrogator takes the machine as human, but we miss a target. Which kind of result, numerically, represents a sufficient score to pass the test? May be that if a machine is taken by the man at least 50% of the times then the test is passed.
Is it a good guess? Probably not, Susan Sterrett, arguing about the Standard interpretation, says: &ldquo;given a skilled and determined interrogator only a human could pass the test&rdquo; [ 7 ], that’s why we are more likely to measure the interrogator skills rather than the machine’s.</p><h2 id=turing-tests-problems-overview>Turing test’s problems overview<a hidden class=anchor aria-hidden=true href=#turing-tests-problems-overview>#</a></h2><p>In the following paragraphs I’am going to present some structural criticism about the Turing test. I will also argue on how each of them applies to both the two interpretations, to support the thesis that the Turing test, whichever interpretation you would like to choose, is structurally ill-posed, hiding intelligence with requirements and expedients which have nothing to do with it as experienced by human beings. The issues I am going to present are the anthropocentrism of the test and the bias towards human intelligence posed by French in [ 3 ], the representation of intelligence as a decision problem and the consequent absence of gradient and some flaws of the game involving the useless pretense to be human even in their defects, the focus on imitating rather than communicating presented by Cullen in [ 1 ] and the subjectivity of the outcome relying it on the interrogator.</p><h2 id=culturally-oriented-human-like-intelligence>Culturally-oriented human-like intelligence<a hidden class=anchor aria-hidden=true href=#culturally-oriented-human-like-intelligence>#</a></h2><p>The first argument against the Turing test, stated by French in [ 3 ], is that not intelligence will pass the Turing test, but only an intelligent entity that has experienced the world as humans do. To clarify the idea behind this thesis I am going to report in brief the parable used by French himself: there are philosophers on a island focused on derive the essential concepts of &ldquo;flying&rdquo;. On that island the only flying entities are seagulls. Unable to get a suitable and complete definition for the phenomenon and knowing the writings of Alan Turing, the philosophers decide to set-up a Turing test-like test for flight, named Seagull test. The Seagull test works much like the Turing test, the philosophers observe the behavior of the seagulls and of the entity under investigation through a radar screen. The entity will be said to have passed the Seagull test if the philosophers are unable to distinguish the two subjects. It’s quite obvious that planes and many different species of birds will never be identified as flying entities by this test. Metaphors aside, the same applies within the Turing test, no entity will get intelligence awarded unless it displays a human-like intelligence.
The argument from French needs to be argued differently under the two versions of the test. Starting from the easiest case, the Standard interpre- tation, the claim from French appears strong. To pass the Standard Turing test a machine has to impersonate a man better than the man itself. We are explicitly looking for human-like intelligence, the goal is to outperform a man in being a man. The Original interpretation needs, instead, a deeper inspection. Here both the man and the machine have to display a behavior which falls outside their habits. In trying to imitate a woman they have to critically think about when and how their answers should be modified.
This approach, not only make the game fairer, but eliminates, as much as possible, the common background of human experience between the man and the woman, trying to isolate the very essence of thinking, such that the man can no more rely on his own experience of the world as human.
Through this expedient the problem is smoothed as much as possible, even if among human beings, there will be an unavoidable common notion of the world and the way we experience it which machines lack.
The point from French presented here lead us to look for the answer to the wrong question, while Turing’s aim was to answer the question &ldquo;Can machines think?&rdquo; the test seems to answer to &ldquo;Can machine think exactly like human beings?&rdquo; which French himself tags as &ldquo;significantly less interesting than the former&rdquo; [ 3 ]. Such strong position from French needs to be discussed, the question &ldquo;Can machine think exactly like human beings?&rdquo; seems way far from being uninteresting since &ldquo;It presumes that we know everything about the way humans think, everything about human intelligence&rdquo; [ 2 ]. Another objection about the whole point from French is based on the fact that &ldquo;general intelligence divorced from our own intelligence is a chimera&rdquo; [ 4 ]. Turing test is undoubtedly testing for human intelligence, and couldn’t be otherwise, at least until we have a general theory of intelligence, which to be developed has for sure to start from the only evidence of intelligence we can study and understand experiencing it everyday, human’s.</p><h2 id=no-gradient-of-intelligence>No gradient of intelligence<a hidden class=anchor aria-hidden=true href=#no-gradient-of-intelligence>#</a></h2><p>Taking for granted that Turing test looks for human intelligence and being fine with it, as argued in the previous section, we can start looking inside the spectrum of human intelligences. The absence of gradient regards how intelligence is perceived against how it is represented, both in the Original and the Standard tests. Starting from an explicative example I will go on arguing about the problem caused by turning intelligence into a decision problem, i.e. a problem that can be posed as a yes-no question of the inputs.
Consider, just for the sake of the example, the Original interpretation of the Turing test, even if there is no particular reason to choose this over the Standard one. We have unchanged the first round of the game, in which a man (A) tries to fool the interrogator (C), in believing he is the woman (B), who in hers turn tries to help C. Now, in the second stage, instead of &ldquo;What will happen when a machine takes the part of A in this game? Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman?&rdquo; we ask ourselves &ldquo;What will happen when a child takes the part of A in this game? Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman?&rdquo;. There are plenty of reasons in believing the answer should be &ldquo;no&rdquo;. Even for children of about 10 years or more, which have already fully developed all their human conversational skills, passing the test remains a mirage. Children for sure don’t lack intelligence nor conversational abilities, so what brings them to failure? They just have not experienced all the aspects of a human life a man had. Imagine any kind of question regarding the sexual sphere, the professional life, or even the task of imitation itself for which a child is probably too naive for, they will put the child in serious troubles. One may argue that in principle, each one of us have a wide range of problematic questions based on the background we have. I agree, but, the arguments that may put in trouble a man are not known a priori, while in the case of the child the interrogator could easily guess them. From this example two conclusions can be drawn, either the child in not intelligent, or the Turing test has a problem in its formulation.The first hypothesis can be discarded, there are no reasons in thinking a child cannot be capable of thoughts while the second holds and the problem is that there isn’t the notion of &ldquo;gradient of intelligence&rdquo; within the test, both the Standard and the Original one. Turing test reduces intelligence to be a binary problem, you can win or lose the game, you can be either intelligent or non-intelligent.
According to the possible outcomes of the Turing test systems are organized in two crisp sets (sets whose membership functions are boolean) the first one representing intelligent systems, the second one representing non-intelligent systems. This is not the way we experience intelligence. We, as humans, are used to rank people about any kind of characteristic and skill, and intelligence is no exception. The way humans experience intelligence is not a matter of crisp sets but fuzzy’s (sets in which the membership function define, not the mere membership or not, but a measure of how strong is this membership). Turing turns a graded problem into a binary problem thresholding it, setting as a threshold the level of intelligence of grown-up humans, not just humans but specifically adults, that’s why children will fail the Turing test. To avoid this problem my view is that has to be devised a multi-task test, like the one described by Cullen in [ 1 ], treating intelligence as an n-dimensional space, whatever it is and whichever are the n features defining that space (is not matter of this discussion trying to derive salient aspects of intelligence).</p><h2 id=encourages-mistakes>Encourages mistakes<a hidden class=anchor aria-hidden=true href=#encourages-mistakes>#</a></h2><p>Imagine a test instance in which the interrogator asks only for mathematical calculations of increasing difficulty. For sure at some point humans will start making errors becoming the task very challenging, while for the machine it would remain rather easy. To mimic humans in doing calculations machines have to introduce deliberately errors, otherwise an interrogator will be easily able to discriminate them. The problem is directly addressed by Turing in [ 8 ], he asks &ldquo;Are they (machines) any worse for that [making no errors in calculations]?&rdquo; The implicit answer &ldquo;no&rdquo;, for the sake of the test, turns out to be &ldquo;yes&rdquo;, within the test it is a weakness that should be avoided. There is a contradiction, there isn’t any reason to penalize machines for handling perfectly mathematical problems, but the test does it. Definitely we are taking away some &ldquo;intelligence&rdquo; to achieve intelligence.
An objection may be that the purpose of the mistakes is to make the machine more human. This objection can be turned out thinking about how humans and machines make such errors. A human doesn’t make errors based on complex statistical models a machine uses. Introducing errors basically embeds in our machine much more non human processes, going down under the surface, than the amount we are taking away. My view is that a good test should preserve qualities rather than introducing complex processes to hide them.
Now let’s look at a practical scenario in which we have an intelligent (according to the Turing test) machine ready to be deployed on the market, probably the first thing the company will do before launching the new product will be to eliminate the voluntary mistakes introduced to mimic humans in doing mathematics. Deliberate errors are just a trick to pass the test, they have nothing to do with intelligence, nor with real world applications.
What argued so far represents a strong objection against the Standard interpretation of the Turing test, since the machine and the man are directly compared, and the &ldquo;imitation&rdquo; task has to be accomplished only by the machine. A test instance as the one presented at the beginning of this section represents a strategy likely to be implemented form the interrogator since his task is to directly discriminate between the two. Regarding the Original interpretation, the issue still apply, and still lead to easily discriminate the machine from others participants, but further considerations about the goal of each player bring us to think that, even if this strategy (still the one described in the example at the beginning of the section of asking only for mathematical calculations) should work, is not so likely to be implemented from an interrogator. May be A a man or a machine, the task of A is to imitate B (woman). Is there something useful, from the interrogator’s perspective, in asking for calculations to distinguish between a woman and a man? In principle not, so this analysis seems strong enough to state that an average interrogator is not so likely to implement this strategy in trying to accomplish his own goal, even if, probably, exploiting it leads to identify
the machine most of the times.</p><h2 id=lying-as-a-key-feature-of-intelligence>Lying as a key feature of intelligence<a hidden class=anchor aria-hidden=true href=#lying-as-a-key-feature-of-intelligence>#</a></h2><p>Whichever interpretation of the test we take into account lying is fundamental in passing it. Makes this lying a key feature of intelligence? Definitely &ldquo;intelligent&rdquo; but too sincere answers lead machines to failure.
Jamie Cullen in [1], describes a scenario in which a game called &ldquo;Guessing game&rdquo; is in place and works as follows: each &ldquo;topic&rdquo; is a word that the &ldquo;interrogator&rdquo; is looking for the machine to reproduce, but without explicitly naming it.
In the instance presented, the topic is &ldquo;stomach&rdquo; and the conversation going on is:</p><ul><li>I :I’m thinking of one of your body parts as the topic.</li><li>M :Ok. What is its function?</li><li>I :it is the place where the food gets digested</li><li>M :I do not eat food. I use batteries for energy. Is this similar?</li><li>I :[&mldr;] Now that I’m aware that you’re not human, perhaps I should correct my earlier statement: The topic is actually a human body part.</li><li>M :Is the topic &ldquo;stomach&rdquo;?</li><li>I :Yes.
In this dialogue the machine shows strong evidence of intelligence, even beyond expectations demonstrating some sort fo self-awareness, moreover the dialogue is carried out successfully since the machine guesses the topic &ldquo;stomach&rdquo;. Setting up and this conversation in the context of the Turing test gives us a machine that exhibits something that seems intelligence, but that
fails in having it granted. Machine revealing itself as machine invalidate all the other accomplishments. That’s why shifting the attention from imitation to communication as proposed by Cullen itself may be a better solution.
&ldquo;The objective of a Communication Test is not to convince an interrogator that an examinee (machine) is a human being, but simply to attempt to achieve a goal via sharing meaning with a conversation partner.&rdquo; [ 1 ]. The idea is to set up a test made of multiple games highlighting different aspects of human interactions, each one scored individually based on the quality of the communication and the accomplishments in these games, to build up a general statistics to be compared to previous runs of the game involving humans. This approach change the paradigm, is not necessary anymore to lie about its own identity, machines are judged on their &ldquo;abilities&rdquo; of being intelligent without any pretense to be human. Being aware of itself, of its own status of machine, may seem a more important feature of intelligence rather than the ability of lying, so communication games needs to be taken into account.</li></ul><h2 id=relies-on-the-subjectivity-of-the-interrogator>Relies on the subjectivity of the interrogator<a hidden class=anchor aria-hidden=true href=#relies-on-the-subjectivity-of-the-interrogator>#</a></h2><p>Within the Turing test, although his role is often forgotten, the influence of the interrogator on the outcome may be way greater than expected. The interrogator, being human, has opinions, desires and biases, which contributes to bring some preconceptions about the outcome. Moreover, not just the mindset but also the skills of the interrogator have an influence. Turing in [ 8 ], defining the interrogator’s characteristics, speaks about &ldquo;average interrogator&rdquo; without further specifications. What &ldquo;average&rdquo; means? We are looking for questioners without a background in AI? or not even any high level of education? or what else? is quite clear that the same game, changing the specification about the interrogator, may become way more, or way less difficult.
Another issue, is that the game, as it is formulated, creates a competition between participants, and the interrogator may be pushed, by human nature, in trying to win it at all costs. Will be a better solution to design a game not centered on a competition but on a mutual-satisfaction as the one proposed by Cullen in [1] assuring a fairer behavior from all the participants.
Looking at the Standard Turing test, the machine and the man are directly competing answering questions from the interrogator, which knows that there’s a machine and a man. Skills and bias are everything in this framework, as already argued, with a sufficient skilled interrogator no machine will ever pass this test. Looking at scores it’s more likely that we’re evaluating interrogator skills rather than machine’s intelligence.
Different considerations can be made for what concern the Original Turing test, here two aspects are crucial, first the task of imitation makes the game fairer, the machine have no more to beat a man in being a man, but to beat a man in imitating a woman, competing in a task in which none of the two is experienced, so both,&ldquo;whatever&rdquo; the question is, have to go back to the very essence of &ldquo;thinking&rdquo; which seems independent from the interrogator. Than, second, a point which is not clear in the Turing’s paper, who, while describing the role of the interrogator in the first round of the test says &ldquo;he (interrogator) knows them (man, woman) by labels X and Y&rdquo;, but than nothing is said about the substitution. Is the interrogator aware of the presence of a machine in the game or still believe the game is played among human beings only? For sure would be better that the interrogator isn’t aware to shield the outcome from the interrogator’s bias and tricks.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>The Turing test, whatever interpretation one takes into account, as argued through this post, suffers some structural issues making us missing the very essence of intelligence, spending too much efforts in building a gaming superstructure which introduces elements completely disconnected from the concept of intelligence. While some of these problems may be neglected, as the French thesis that the test is focused towards human intelligence, which is actually true but, as argued, no alternatives are on the table until a comprehensive theory of intelligence will be available, which in its turn seems reasonable to be derived form a comprehensive theory of human intelligence, some others applies and are due, not to the idea of turning the question &ldquo;Can machines think?&rdquo; into a game, but to the framework of that particular game which poses intelligence as a binary problem, focused on deceiving rather than communicating and relying on a subjective judgment.
For what concern the two versions of the test specifically, from what argued along this blog post I can safely state, in accordance with Susan Sterrett, that for sure the Original version is way more robust and reliable, &ldquo;despite the similarity of the two tests, the first test is vastly superior&rdquo; [ 7 ] , even if unfortunately nowadays the most widespread notion of Turing test is the Standard one.
As a real world evidence of the misleading path forced by the Turing test structure, we can take look at some results coming from the Loebner Prize competition. The Loebner prize is &ldquo;an annual contest between computer programs to identify the most human programs, and eventually to award $100,000 to the program that first passes an unrestricted Turing test&rdquo; [ 5 ].
Historically, most of the famous bots which have gained attention within the competition, such as ELIZA and PARRY, resort to tricks suited to fool human minds rather than implementing true intelligence. ELIZA is a chatbot proposed by Joseph Weisenbaum in 1966, which fools some judges in believing it is human by answering to questions with questions to continuously change the topic avoiding contradictions, &ldquo;this works because most people like to talk about themselves, and are happy to believe the program is listening.&rdquo; [ 5 ]. PARRY written in 1972 by Kenneth Colby, simulates paranoid people and alternates times in which continuously change the topic to times in which it goes deep in specific stories embedded in its memory, and moreover it does not try to give an answer to everything, sometimes it just admit ignorance answering &ldquo;I don’t know&rdquo;. None of the two chatbots is
intelligent, both implement nothing more than if then else rules, they just
know how to deceive humans exploiting their weaknesses.
As shown through these examples, using the Turing test as our tool towards machine intelligence, may drive us out of the way. If research totally commits its efforts in passing the Turing test it’s likely that we will find new tricks rather than intelligence. &ldquo;We won’t learn much about AI from Loebner Prize but we will learn some non negligible things about social psychology&rdquo; [ 6 ].</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p><strong>1.</strong> Jamie Cullen. Imitation versus communication: Testing for human-like
intelligence.Minds and Machines, 19(2):237–254, 2009.
<strong>2.</strong> Adam Drozdek. Human intelligence and turing test. AI and Society,
12(4):315–321, 1998.
<strong>3.</strong> Robert M. French. Subcognition and the limits of the turing test.Mind,
99(393):53–66, 1990.
<strong>4.</strong> David Hillel. Gelernter. The muse in the machine: computers and creative
thought / david gelernter. pages 149–162, 1994.
<strong>5.</strong> Michael L. Mauldin. Chatterbots, tinymuds, and the turing test: Entering
the loebner prize competition. pages 16–21, 1994.
<strong>6.</strong> Stuart M. Shieber. Lessons from a restricted turing test.Commun. ACM,
37(6):70–78, June 1994.
<strong>7.</strong> Susan G. Sterrett. Turing’s two tests for intelligence.Minds and Machines,
10(4):541–559, 2000.
<strong>8.</strong> Alan M. Turing. Computing machinery and intelligence. Mind,
59(October):433–60, 1950.</p></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test on x" href="https://x.com/intent/tweet/?text=Structural%20issues%20of%20the%20Turing%20test%3a%20A%20survey%20on%20the%20structural%20issues%20concerning%20two%20different%20interpretations%20of%20the%20Turing%20test&amp;url=https%3a%2f%2ffabfiles.github.io%2fposts%2fstructural_issues_turing_test%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2ffabfiles.github.io%2fposts%2fstructural_issues_turing_test%2f&amp;title=Structural%20issues%20of%20the%20Turing%20test%3a%20A%20survey%20on%20the%20structural%20issues%20concerning%20two%20different%20interpretations%20of%20the%20Turing%20test&amp;summary=Structural%20issues%20of%20the%20Turing%20test%3a%20A%20survey%20on%20the%20structural%20issues%20concerning%20two%20different%20interpretations%20of%20the%20Turing%20test&amp;source=https%3a%2f%2ffabfiles.github.io%2fposts%2fstructural_issues_turing_test%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ffabfiles.github.io%2fposts%2fstructural_issues_turing_test%2f&title=Structural%20issues%20of%20the%20Turing%20test%3a%20A%20survey%20on%20the%20structural%20issues%20concerning%20two%20different%20interpretations%20of%20the%20Turing%20test"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ffabfiles.github.io%2fposts%2fstructural_issues_turing_test%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test on whatsapp" href="https://api.whatsapp.com/send?text=Structural%20issues%20of%20the%20Turing%20test%3a%20A%20survey%20on%20the%20structural%20issues%20concerning%20two%20different%20interpretations%20of%20the%20Turing%20test%20-%20https%3a%2f%2ffabfiles.github.io%2fposts%2fstructural_issues_turing_test%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test on telegram" href="https://telegram.me/share/url?text=Structural%20issues%20of%20the%20Turing%20test%3a%20A%20survey%20on%20the%20structural%20issues%20concerning%20two%20different%20interpretations%20of%20the%20Turing%20test&amp;url=https%3a%2f%2ffabfiles.github.io%2fposts%2fstructural_issues_turing_test%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Structural issues of the Turing test: A survey on the structural issues concerning two different interpretations of the Turing test on ycombinator" href="https://news.ycombinator.com/submitlink?t=Structural%20issues%20of%20the%20Turing%20test%3a%20A%20survey%20on%20the%20structural%20issues%20concerning%20two%20different%20interpretations%20of%20the%20Turing%20test&u=https%3a%2f%2ffabfiles.github.io%2fposts%2fstructural_issues_turing_test%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://fabfiles.github.io/>FabFiles</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>